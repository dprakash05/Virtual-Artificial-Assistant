{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8a0502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folowing are packasges need to install to run this program.\n",
    "#pip install SpeechRecognition\n",
    "#pip install pyttsx3\n",
    "#pip install pywhatkit\n",
    "#pip install wikipedia\n",
    "#pip install pyjokes\n",
    "#pip install jinja2\n",
    "#pip install PyAudio\n",
    "#pip install wolframalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48855e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from markupsafe import escape\n",
    "#pip install wolframalpha -- from anaconda propt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5440e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install PyAudio-0.2.11-cp39-cp39-win_amd64.whl\n",
    "# from https://www.lfd.uci.edu/~gohlke/pythonlibs/#pyaudio\n",
    "#pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d7fdfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import pandas as pd\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import wikipedia\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d050ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import pyaudio\n",
    "import pyjokes\n",
    "import pywhatkit\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9330da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f13c97f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install ecapture - from promt\n",
    "#pip install twilio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c64175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import wolframalpha\n",
    "from twilio.rest import Client\n",
    "#from clint.textui import progress\n",
    "#from ecapture import ecapture as ec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90cc3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd09e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bef4340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Speech\\Voices\\Tokens\\TTS_MS_EN-US_ZIRA_11.0\n"
     ]
    }
   ],
   "source": [
    "engine=pyttsx3.init('sapi5')\n",
    "voices=engine.getProperty('voices')\n",
    "print(voices[2].id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9530c66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.setProperty('voice',voices[2].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddd2a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "speak('how are you')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d99552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will greet\n",
    "def wishme():\n",
    "    hour=int(datetime.datetime.now().hour)\n",
    "    if hour>=0 and hour <12:\n",
    "        speak('good morning')\n",
    "    elif hour>=12 and hour<16:\n",
    "        speak('good afternoon')\n",
    "    elif hour >=16 and hour<19:\n",
    "        speak('good evening')\n",
    "    else:\n",
    "        speak('good night')\n",
    "    speak('I am VAI, your virtual artificial intelegence, how may i help you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "871f5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wishme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e496ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will take command from user\n",
    "def takecommand():\n",
    "    r=sr.Recognizer()\n",
    "\n",
    "    with sr.Microphone() as source:\n",
    "        print('listening..')\n",
    "        r.pause_threshold=1\n",
    "        audio=r.listen(source) \n",
    "    try:\n",
    "        print('recognizing')\n",
    "        query=r.recognize_google(audio,language='en-in')\n",
    "        print(f'user said:{query}\\n')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('say that again please')\n",
    "        return 'None'\n",
    "    return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "535727b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Go to newsapi.org\n",
    "Create account where you will get api key\n",
    "paste in url your api key\n",
    "\"\"\"\n",
    "\n",
    "def news():\n",
    "    main_url='https://newsapi.org/v2/top-headlines?sources=techcrunch&apikey=c03e1581b08d4921b5d082aef0a11b80'\n",
    "    main_page=requests.get(main_url).json()\n",
    "    #print(main_page)\n",
    "    articles=main_page['articles']\n",
    "    #print(articles)\n",
    "    head=[]\n",
    "    day=['first','second','third','fourth','fifth']\n",
    "    for ar in articles:\n",
    "        head.append(ar['title'])\n",
    "    for i in range(len(day)):\n",
    "        print(f'todays {day[i]} news is :{head[i]}')\n",
    "        speak(f'todays {day[i]} news is :{head[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36109b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "487d648b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"2.2.0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0m__MODEL_HUB_ORGANIZATION__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sentence-transformers'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mLoggingHandler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLoggingHandler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSentenceTransformer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\datasets\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mDenoisingAutoEncoderDataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDenoisingAutoEncoderDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mNoDuplicatesDataLoader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoDuplicatesDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mParallelSentencesDataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallelSentencesDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSentencesDataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentencesDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mSentenceLabelDataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentenceLabelDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sentence_transformers\\datasets\\DenoisingAutoEncoderDataset.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInputExample\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInputExample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;31m# [RFC-0016](https://github.com/pytorch/rfcs/pull/27) for more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m \u001b[1;31m# information.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_masked\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_masked\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_apply_docstring_templates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m def sum(input: Tensor,\n\u001b[0m\u001b[0;32m    421\u001b[0m         \u001b[0mdim\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDimOrDims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_masked\\__init__.py\u001b[0m in \u001b[0;36m_apply_docstring_templates\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    264\u001b[0m                      \u001b[1;34m'operation_kwargs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'__'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moperation_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                      \u001b[1;31m# one-line representation of a tensor:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                      \u001b[1;34m'example_input'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m                      \u001b[1;34m'example_args'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexample_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                      \u001b[1;34m'example_mask'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    303\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# All strings are unicode in Python 3.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_str_intern\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_str_intern\u001b[1;34m(inp)\u001b[0m\n\u001b[0;32m    407\u001b[0m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m                     \u001b[0mtensor_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayout\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrided\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_formatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimag_formatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_summarized_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msummarize\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_tensor_str_with_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor_str.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mtensor_view\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating_dtype\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f0c4cf5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SentenceTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SentenceTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load transformer models\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "df=pd.read_csv('question_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c352c0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_search(ques, emmbding_df, conf):\n",
    "    \"\"\"\n",
    "    Obj: This function is used to check the similar question from the databases\n",
    "    useing embeddings.\n",
    "    :param ques: input question\n",
    "    :param emmbding_df: data frame which contains embeddings for all the question\n",
    "    :param conf: confidence\n",
    "    :return: list of similar questions\n",
    "    \"\"\"\n",
    "    ques = [ques]\n",
    "    # extract embeddings for  all question\n",
    "    sentence_embd = emmbding_df[\"embd\"].to_list()\n",
    "    # create embeddings for questions\n",
    "    question_embd = model.encode(ques, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine-similarities for each sentence with each other sentence\n",
    "    cosine_scores = util.cos_sim(sentence_embd, question_embd)\n",
    "\n",
    "    emmbding_df[\"score\"] = [round(float(score), 2) for score in cosine_scores]  # remove\n",
    "    result = emmbding_df[emmbding_df[\"score\"] >= conf].reset_index(drop=True)\n",
    "    # convert all question into list\n",
    "    sq = result[\"Question\"].to_list()\n",
    "    return sq\n",
    "df[\"embd\"] = df[\"embd\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f38426e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"embd\"] = df[\"embd\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58aacad3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listening..\n",
      "recognizing\n",
      "user said:open camera\n",
      "\n",
      "listening..\n",
      "recognizing\n",
      "user said:make sentence using automatic\n",
      "\n",
      "listening..\n",
      "recognizing\n",
      "\n",
      "say that again please\n",
      "listening..\n",
      "recognizing\n",
      "user said:I like how did you come on this\n",
      "\n",
      "listening..\n",
      "recognizing\n",
      "\n",
      "say that again please\n",
      "listening..\n",
      "recognizing\n",
      "\n",
      "say that again please\n",
      "listening..\n",
      "recognizing\n",
      "user said:don't listen\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function BSTR.__del__ at 0x000001AA9CB190D0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\lib\\site-packages\\comtypes\\__init__.py\", line 999, in __del__\n",
      "    def __del__(self, _free=windll.oleaut32.SysFreeString):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'takeCommand' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10484/2771345869.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;34m\"don't listen\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m\"stop listening\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mspeak\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"for how much time you want to stop VAI from listening commands\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtakeCommand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'takeCommand' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" We can give command like search in wikipedia, open youtube and play music, play song in youtube.\n",
    "we can ask current time,jokes and translate in any language, I have selected Hindi language.\n",
    "we can extract similarity snetences from embeded dataframe using cosine similarity.\n",
    "\"\"\"\n",
    "while True:\n",
    "    query=takecommand().lower()\n",
    "\n",
    "    if  'who is' in query:\n",
    "        speak('searching wikipedia...')\n",
    "        query=query.replace('wikipedia','')\n",
    "        results=wikipedia.summary(query,sentences=2)\n",
    "        speak('according to wikipedia')\n",
    "        print(results)\n",
    "        speak(results)\n",
    "    elif 'open youtube' in query:\n",
    "        webbrowser.open('youtube.com')\n",
    "    elif 'open google' in query:\n",
    "        webbrowser.open('google.com')\n",
    "    elif 'play music' in query:\n",
    "        music_dir='D:\\\\songs'\n",
    "        songs=os.listdir(music_dir)\n",
    "        rd=random.choice(songs)\n",
    "        os.startfile(os.path.join(music_dir,rd))\n",
    "        print(songs)\n",
    "        os.startfile(os.path.join(music_dir,songs[0]))\n",
    "    elif 'time' in query:\n",
    "        strTime=datetime.datetime.now().strftime('%H:%M:%S')\n",
    "        speak(f'time is {strTime}')\n",
    "    elif 'play' in query:\n",
    "        song = query.replace('play', '')\n",
    "        speak (song)\n",
    "        pywhatkit.playonyt(song)\n",
    "    elif 'joke' in query:\n",
    "        jokes=(pyjokes.get_joke())\n",
    "        print(jokes)\n",
    "        speak(jokes) \n",
    "    elif 'similarity' in query:\n",
    "        que=query.replace('similarity','')\n",
    "        print(que)\n",
    "        res = question_search(que, df, conf=0.40)\n",
    "        #sq = res[\"Question\"].to_list()\n",
    "        print(\"Similar questions found...\")\n",
    "        for i in res:\n",
    "            print(i)\n",
    "            speak(i)\n",
    "        \n",
    "    elif 'temperature' in query:\n",
    "        speak('searching temperature')\n",
    "        temp='temperature in mumbai'\n",
    "        url=f'https://google.com/search?q={temp}'\n",
    "        rs=requests.get(url)\n",
    "        data=BeautifulSoup(rs.text,'html.parser' )\n",
    "        temps=data.find('div', class_='BNeawe').text\n",
    "        print(temps)\n",
    "        speak(f'currenr {temp} is {temps}')\n",
    "    elif 'translate' in query:\n",
    "        translator=Translator()\n",
    "        sen=query.replace('translate','')\n",
    "        sen=translator.translate(sen,src='en',dest='hi')\n",
    "        print(sen)\n",
    "        speak(sen.pronunciation)\n",
    "    elif 'send message' in query:\n",
    "        pywhatkit.sendwhatmsg_instantly('+919820676422','this is test message')\n",
    "    elif 'exit' in query:\n",
    "        break\n",
    "    elif 'open camera' in query:\n",
    "        cap=cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            ret,img=cap.read()\n",
    "            cv2.imshow('webcam',img)\n",
    "            if cv2.waitKey(1)& 0xFF==ord('q'):\n",
    "           # k=cv2.waitKey(50)\n",
    "            #if k==27:\n",
    "            # press q foe quit\n",
    "                break;\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    elif 'news' in query:\n",
    "        news()\n",
    "    elif \"don't listen\" in query or \"stop listening\" in query:\n",
    "            speak(\"for how much time you want to stop VAI from listening commands\")\n",
    "            a = int(takeCommand())\n",
    "            time.sleep(a)\n",
    "            print(a)\n",
    "    elif \"where is\" in query:\n",
    "            query = query.replace(\"where is\", \"\")\n",
    "            location = query\n",
    "            speak(\"User asked to Locate\")\n",
    "            speak(location)\n",
    "            webbrowser.open(\"https://www.google.com/maps/place/'\" + location + \"\")\n",
    "            #('https://www.google.com/maps/place/' + map_string)\n",
    "    elif \"calculate\" in query:\n",
    "             \n",
    "            app_id = \"5QVV3E-GYRWXY8UV5\"\n",
    "            client = wolframalpha.Client(app_id)\n",
    "            indx = query.lower().split().index('calculate')\n",
    "            query = query.split()[indx + 1:]\n",
    "            res = client.query(' '.join(query))\n",
    "            answer = next(res.results).text\n",
    "            print(\"The answer is \" + answer)\n",
    "            speak(\"The answer is \" + answer)\n",
    "\"\"\"wolframalpha- we can calculate, find GDP ,weather,conversion almost anything we can ask from it.\n",
    "\"\"\"\n",
    "\n",
    "#APPID: 5QVV3E-GYRWXY8UV5\n",
    "     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d52ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#<div jscontroller=\"e0Sh5\" class=\"Ab33Nc\" aria-level=\"3\" role=\"heading\"><div><div class=\"vk_bk TylWce SGNhVe\"><span class=\"wob_t q8U8x\" id=\"wob_tm\" sty\n",
    "# <div class=\"vk_bk TylWce SGNhVe\"><span class=\"wob_t q8U8x\" id=\"wob_tm\" style=\"display:inline\">27</span><span class=\"wob_t\" id=\"wob_ttm\" style=\"display:none\">81</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e5c6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('question_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd2e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94876d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(audio):\n",
    "\tengine.say(audio)\n",
    "\tengine.runAndWait()\n",
    "\n",
    "def wishMe():\n",
    "\thour = int(datetime.datetime.now().hour)\n",
    "\tif hour>= 0 and hour<12:\n",
    "\t\tspeak(\"Good Morning Sir !\")\n",
    "\n",
    "\telif hour>= 12 and hour<18:\n",
    "\t\tspeak(\"Good Afternoon Sir !\")\n",
    "\n",
    "\telse:\n",
    "\t\tspeak(\"Good Evening Sir !\")\n",
    "\n",
    "\tassname =(\"Jarvis 1 point o\")\n",
    "\tspeak(\"I am your Assistant\")\n",
    "\tspeak(assname)\n",
    "\t\n",
    "\n",
    "def username():\n",
    "\tspeak(\"What should i call you sir\")\n",
    "\tuname = takeCommand()\n",
    "\tspeak(\"Welcome Mister\")\n",
    "\tspeak(uname)\n",
    "\tcolumns = shutil.get_terminal_size().columns\n",
    "\t\n",
    "\tprint(\"#####################\".center(columns))\n",
    "\tprint(\"Welcome Mr.\", uname.center(columns))\n",
    "\tprint(\"#####################\".center(columns))\n",
    "\t\n",
    "\tspeak(\"How can i Help you, Sir\")\n",
    "\n",
    "def takeCommand():\n",
    "\t\n",
    "\tr = sr.Recognizer()\n",
    "\t\n",
    "\twith sr.Microphone() as source:\n",
    "\t\t\n",
    "\t\tprint(\"Listening...\")\n",
    "\t\tr.pause_threshold = 1\n",
    "\t\taudio = r.listen(source)\n",
    "\n",
    "\ttry:\n",
    "\t\tprint(\"Recognizing...\")\n",
    "\t\tquery = r.recognize_google(audio, language ='en-in')\n",
    "\t\tprint(f\"User said: {query}\\n\")\n",
    "\n",
    "\texcept Exception as e:\n",
    "\t\tprint(e)\n",
    "\t\tprint(\"Unable to Recognize your voice.\")\n",
    "\t\treturn \"None\"\n",
    "\t\n",
    "\treturn query\n",
    "\n",
    "def sendEmail(to, content):\n",
    "\tserver = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "\tserver.ehlo()\n",
    "\tserver.starttls()\n",
    "\t\n",
    "\t# Enable low security in gmail\n",
    "\tserver.login('your email id', 'your email password')\n",
    "\tserver.sendmail('your email id', to, content)\n",
    "\tserver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f107fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing...\n",
      "User said: Alpha Alpha\n",
      "\n",
      "                                                 #####################                                                  \n",
      "Welcome Mr.                                                       Alpha Alpha                                                       \n",
      "                                                 #####################                                                  \n"
     ]
    }
   ],
   "source": [
    "username()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ecc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09424f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# load transformer models\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43857d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_search(ques, emmbding_df, conf):\n",
    "    \"\"\"\n",
    "    Obj: This function is used to check the similar question from the databases\n",
    "    useing embeddings.\n",
    "    :param ques: input question\n",
    "    :param emmbding_df: data frame which contains embeddings for all the question\n",
    "    :param conf: confidence\n",
    "    :return: list of similar questions\n",
    "    \"\"\"\n",
    "    ques = [ques]\n",
    "    # extract embeddings for  all question\n",
    "    sentence_embd = emmbding_df[\"embd\"].to_list()\n",
    "    # create embeddings for questions\n",
    "    question_embd = model.encode(ques, convert_to_tensor=True)\n",
    "\n",
    "    # Compute cosine-similarities for each sentence with each other sentence\n",
    "    cosine_scores = util.cos_sim(sentence_embd, question_embd)\n",
    "\n",
    "    emmbding_df[\"score\"] = [round(float(score), 2) for score in cosine_scores]  # remove\n",
    "    result = emmbding_df[emmbding_df[\"score\"] >= conf].reset_index(drop=True)\n",
    "    # convert all question into list\n",
    "    sq = result[\"Question\"].to_list()\n",
    "    return sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b5199",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"embd\"] = df[\"embd\"].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726983b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = question_search(que, df, conf=0.40)\n",
    "#sq = res[\"Question\"].to_list()\n",
    "print(\"Similar questions found...\")\n",
    "for i in res:\n",
    "    print(i)\n",
    "    speak(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83621ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ee7aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f475e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    translator=Translator()\n",
    "    sen=translator.translate(text,src='en',dest='hi')\n",
    "    print(sen.text)\n",
    "    return sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af995ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=translator.translate('आप कैसे हैं')\n",
    "print(a.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google_trans_new import google_translator  \n",
    "  \n",
    "# translator = google_translator()  \n",
    "# translate_text = translator.translate('Hola mundo!', lang_src='es', lang_tgt='en')  \n",
    "# print(translate_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcb5673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp='temperture in mubai'\n",
    "# url=f'https://google.com/search?q={temp}'\n",
    "# rs=requests.get(url)\n",
    "# data=BeautifulSoup(rs.text,'html.parser' )\n",
    "# temps=data.find('div', class_='BNeawe').text\n",
    "# print(temps)\n",
    "# speak(f'current {temp} is {temps}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
